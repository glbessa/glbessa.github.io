import React from 'react';
import PostDetailLayout from '../../components/PostDetailLayout';

export const metadata = {
  "title": "Arquitetura U-Net",
  "author": "Gabriel Leite Bessa",
  "tags": [
    "posts",
    "deep_learning",
    "computer_vision",
    "ai"
  ],
  "date": "2023-07-21",
  "hero": "/posts/unet_architecture/img/u-net-architecture.png",
  "description": "Postagem sobre a arquitetura UNet",
  "slug": "unet_architecture"
};

export const content = `## Introdu√ß√£o

O desenvolvimento de redes neurais profundas cresceu muito nos √∫ltimos anos gra√ßas ao aumento da quantidade de dados dispon√≠veis, ao aumento do poder computacional e os obst√°culos que as t√©cnicas de machine learning cl√°ssica come√ßaram a enfrentar, chegando a um limite no aprendizado com essas t√©cnicas. Isso passou  a ter um papel ess√™ncial em tarefas de vis√£o computacional com a cria√ß√£o das redes neurais convolucionais, que diferente das feed-forward neural networks, fazem o uso de filtros convolucionais para o aprendizado de caracter√≠sticas em imagens. Com isso, redes totalmente convolucionais come√ßaram a surgir tamb√©m, nas quais todas as partes da rede s√£o compostas por camadas de convolu√ß√£o, sendo a U-Net uma dessas redes.

A seguir s√£o apresentados alguns exemplos de tarefas de vis√£o computacional:

![Figura 1: Exemplos de tarefas de vis√£o computacional.](/posts/unet_architecture/img/different_types_of_computer_vision_tasks.webp)

## Arquitetura U-Net

A U-Net √© uma rede neural convolucional criada para segmenta√ß√£o de imagens com foco em imagens biom√©dicas, sendo baseada em uma rede totalmente convolucional e optimizada para trabalhar com um dataset de treinamento pequeno obtendo ainda sim bons resultados. A ideia principal da rede √© ter camadas de contra√ß√£o e ap√≥s ter camadas de expans√£o para que assim consiga realizar o trabalho de segmenta√ß√£o das imagens, sendo a primeira parte tamb√©m chamada de decoder e a segunda parte de encoder.

![Figura 2: Encoder e decoder com skip connections.](/posts/unet_architecture/img/encoder_decoder_with_skip_connections.webp)

A camada de contra√ß√£o realiza a extra√ß√£o das caracter√≠sticas da imagem, aumentando o n√∫mero de canais ap√≥s cada camada. Essa parte realiza duas convolu√ß√µes com filtros 3x3 e fun√ß√£o de ativa√ß√£o ReLU, no artigo original da U-Net essas convolu√ß√µes n√£o apresentam nenhum preenchimento (padding), entretanto isso acaba por reduzir o tamanho das m√°scaras de sa√≠da, e muitas vezes n√£o √© seguido em outras implementa√ß√µes. Ap√≥s essas duas camadas de convolu√ß√£o existe uma camada de *max-pooling* com filtro 2x2, que faz a redu√ß√£o da resolu√ß√£o da imagem pela metade. Ao final existe ainda uma camada de *dropout* de 30% de probabilidade.

> üí° **Note:** Dropout: a camada de dropout √© respons√°vel por reduzir o overfitting e melhorar a generaliza√ß√£o no dataset de teste eliminando alguns neur√¥nios com determinada probabilidade

![Figura 3: Camada de dropout](/posts/unet_architecture/img/dropout.png)

> üí° **Note:** Fun√ß√£o de ativa√ß√£o: A fun√ß√£o de ativa√ß√£o √© respons√°vel por tornar a rede capaz de modelar fun√ß√µes n√£o lineares.

![Figura 4: Fun√ß√£o de ativa√ß√£o ReLU](/posts/unet_architecture/img/relu.jpg)

J√° camada de expans√£o realiza a o v√≠nculo dessas caracter√≠sticas com informa√ß√µes espaciais da imagem. Sendo composta por uma camada de convolu√ß√£o upsample com stride igual a 2, uma camada de concatena√ß√£o, que √© usada para as skip connections, uma camada de *dropout* de 30% e duas camadas de convolu√ß√£o com filtro 3x3 e fun√ß√£o de ativa√ß√£o ReLU.

As camadas de contra√ß√£o e expans√£o s√£o ligadas por skip connections que s√£o ess√™nciais em redes neurais com muitas camadas, pois elas passam para camadas posteriores o contexto anterior e melhoram o aprendizado, sendo muito melhor a converg√™ncia de redes que a utilizam.

Ao final da rede existe uma camada de convolu√ß√£o com filtro 1x1 e fun√ß√£o de ativa√ß√£o *softmax* que realiza a classifica√ß√£o dos pixels da imagem. Sendo a mesma opera√ß√£o que uma camada de feed-forward dense. 

![Figura 5: Arquitetura da rede U-Net.](/posts/unet_architecture/img/u-net-architecture.png)

## Implementa√ß√£o da U-Net com Tensorflow

A seguir √© demostrada um exemplo de implementa√ß√£o da rede U-Net utilizando Tensorflow. No exemplo os block de contra√ß√£o e expans√£o foram definidos em duas fun√ß√µes, *downsample_block* e *upsample_block* respectivamente.

\`\`\`python
def downsample_block(x, n_filters, n_channels=1):
    x = layers.Conv2D(n_filters, n_channels, strides = 1, padding = "same", activation = "relu")(x)
    x = layers.Conv2D(n_filters, n_channels, strides = 1, padding = "same", activation = "relu")(x)
    p = layers.MaxPool2D(2)(x)
    p = layers.Dropout(0.3)(p)

    return f, p
\`\`\`

\`\`\`python
def upsample_block(x, conv_features, n_filters, n_channels=1):
    x = layers.Conv2DTranspose(n_filters, n_channels, strides=2, padding="same")(x)
    x = layers.concatenate([x, conv_features])
    x = layers.Dropout(0.3)(x)
    x = layers.Conv2D(n_filters, n_channels, strides = 1, padding = "same", activation = "relu")(x)
    x = layers.Conv2D(n_filters, n_channels, strides = 1, padding = "same", activation = "relu")(x)

    return x
\`\`\`

Ao final √© feito o uso dessas fun√ß√µes e a constru√ß√£o da rede em si:


\`\`\`python
def build_unet_model(shape:tuple, n_classes:int):
    inputs = layers.Input(shape=shape)
    n_channels = shape[-1]

    # encoder: contracting path - downsample
    # 1 - downsample
    f1, p1 = downsample_block(inputs, 32, n_channels)
    # 2 - downsample
    f2, p2 = downsample_block(p1, 64, n_channels)
    # 3 - downsample
    f3, p3 = downsample_block(p2, 128, n_channels)
    # 4 - downsample
    f4, p4 = downsample_block(p3, 256, n_channels)
    # 5 - downsample
    f5, p5 = downsample_block(p4, 512, n_channels)

    # 6 - bottleneck
    bottleneck = double_conv_block(p5, 1024, n_channels)

    # decoder: expanding path - upsample
    # 7 - upsample
    u7 = upsample_block(bottleneck, f5, 512, n_channels)
    # 8 - upsample
    u8 = upsample_block(u7, f4, 256, n_channels)
    # 9 - upsample
    u9 = upsample_block(u8, f3, 128, n_channels)
    # 10 - upsample
    u10 = upsample_block(u9, f2, 64, n_channels)
    # 11 - upsample
    u11 = upsample_block(u10, f1, 32, n_channels)

    # outputs
    outputs = layers.Conv2D(n_classes, (1, 1), padding="same", activation = "softmax")(u11)

    # unet model with Keras Functional API
    unet_model = tf.keras.Model(inputs, outputs, name="U-Net")

    return unet_model
\`\`\`

## Refer√™ncias

Figura 1 por [Minh Tran]("https://towardsdatascience.com/understanding-u-net-61276b10f360")

Figura 2 por [Minh Tran]("https://towardsdatascience.com/understanding-u-net-61276b10f360")

Figura 3 por [Nitish](https://jmlr.org/papers/volume15/srivastava14a/srivastava14a.pdf)

Figura 4 por []()

Figura 5 por [U-Net creators](https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/)

[Understanding U-Net](https://towardsdatascience.com/understanding-u-net-61276b10f360)

[Introduction to ResNets](https://towardsdatascience.com/introduction-to-resnets-c0a830a288a4)

[C4W1L04 Padding](https://www.youtube.com/watch?v=smHa2442Ah4)

[An Introduction to different Types of Convolutions in Deep Learning](https://towardsdatascience.com/types-of-convolutions-in-deep-learning-717013397f4d)

[U-Net: Convolutional Networks for Biomedical Image Segmentation](https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/)

[U-Net: Wikip√©dia](https://en.wikipedia.org/wiki/U-Net)

[U-Net: Paper with code](https://paperswithcode.com/method/u-net)

[Camadas de Pooling em Redes Neurais Convolucionais](https://www.deeplearningbook.com.br/camadas-de-pooling-em-redes-neurais-convolucionais/)

[Introdu√ß√£o √†s Redes Neurais Convolucionais](https://www.deeplearningbook.com.br/introducao-as-redes-neurais-convolucionais/)

[Dropout in Neural Networks](https://towardsdatascience.com/dropout-in-neural-networks-47a162d621d9)

[C4W2L04 Why ResNets Work](https://www.youtube.com/watch?v=RYth6EbBUqM)

[Fun√ß√µes de ativa√ß√£o: defini√ß√£o, caracter√≠sticas, e quando usar cada uma](https://iaexpert.academy/2020/05/25/funcoes-de-ativacao-definicao-caracteristicas-e-quando-usar-cada-uma/?doing_wp_cron=1690209521.0830559730529785156250)`;

export default function Post() {
  return <PostDetailLayout data={{...metadata, content}} type="posts" />;
}
